{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Layer 6 SDAE for text embedding\n",
    "ref) Zhang, Fuzheng, et al. \"Collaborative knowledge base embedding for recommender systems.\" Proceedings of the 22nd ACM SIGKDD International Conference on Knowledge Discovery and Data Mining. ACM, 2016."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import numpy as np\n",
    "import os\n",
    "import pickle\n",
    "from time import time\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.examples.tutorials.mnist import input_data\n",
    "from tensorflow.python.framework import ops\n",
    "\n",
    "from BatchGenerator import BatchGenerator\n",
    "import param"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with open('Amazon/bow_mtx.pkl', 'rb') as f:\n",
    "    bow_mtx = pickle.load(f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "ops.reset_default_graph()\n",
    "sess = tf.Session()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "input_dim = bow_mtx.shape[1]\n",
    "# input_dim = 43735\n",
    "# input_dim = 3000"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# batch_size = param.batch_size\n",
    "batch_size = param.batch_size\n",
    "iter_time = param.iter_time"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "lambda_W = param.lambda_W\n",
    "lambda_b = param.lambda_b\n",
    "lambda_X = param.lambda_X\n",
    "hidden_dim = param.hidden_dim\n",
    "dim = param.dim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "learning_rate = param.learning_rate"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "sample_mtx = bow_mtx[:, :input_dim]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "---"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "x_data = tf.placeholder(dtype=tf.float32, shape = [batch_size, input_dim])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def denoise(x_data):\n",
    "    noise = tf.Variable(tf.random_normal(shape = [batch_size, input_dim]), name=\"noise\")\n",
    "    return tf.add(noise, x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"Denoise\") as scope:\n",
    "    X0 = denoise(x_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def e_layer_1(X0):\n",
    "    W1 = tf.Variable(tf.random_normal(shape = [input_dim, hidden_dim], mean = 0., stddev = 1/lambda_W), name = 'W1')\n",
    "    b1 = tf.Variable(tf.random_normal(shape = [batch_size, hidden_dim], mean = 0., stddev = 1/lambda_b), name = 'b1')\n",
    "    output1 = tf.nn.sigmoid(tf.add(tf.matmul(X0, W1), b1), name = 'output1')\n",
    "    X1 = tf.random_normal(shape = [batch_size, hidden_dim], mean = output1, stddev = 1/lambda_X, name = 'X1')\n",
    "    return output1, X1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"e_layer_1\") as scope:\n",
    "    output1, X1 = e_layer_1(X0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def e_layer_2(X1):\n",
    "    W2 = tf.Variable(tf.random_normal(shape = [hidden_dim, hidden_dim], mean = 0., stddev = 1/lambda_W), name = 'W2')\n",
    "    b2 = tf.Variable(tf.random_normal(shape = [batch_size, hidden_dim], mean = 0., stddev = 1/lambda_b), name = 'b2')\n",
    "    output2 = tf.nn.sigmoid(tf.add(tf.matmul(X1, W2), b2), name = 'output2')\n",
    "    X2 = tf.random_normal(shape = [batch_size, hidden_dim], mean = output2, stddev = 1/lambda_X, name = 'X2')\n",
    "    return output2, X2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"e_layer_2\") as scope:\n",
    "    output2, X2 = e_layer_2(X1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def e_layer_3(X2):\n",
    "    W3 = tf.Variable(tf.random_normal(shape = [hidden_dim, dim], mean = 0, stddev = 1/lambda_W), name = 'W3')\n",
    "    b3 = tf.Variable(tf.random_normal(shape = [batch_size, dim], mean = 0., stddev = 1/lambda_b), name = 'b3')\n",
    "    output3 = tf.nn.sigmoid(tf.add(tf.matmul(X2, W3), b3), name = 'output3')\n",
    "    X3_ = tf.random_normal(shape = [batch_size, dim], mean = output3, stddev = 1/lambda_X, name = 'X3_')\n",
    "    return output3, X3_"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"e_layer_3\") as scope:\n",
    "    output3, X3_ = e_layer_3(X2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d_layer_1(X3_):\n",
    "    W4 = tf.Variable(tf.random_normal(shape = [dim, hidden_dim], mean = 0., stddev = 1/lambda_W), name = 'W4')\n",
    "    b4 = tf.Variable(tf.random_normal(shape = [batch_size, hidden_dim], mean = 0., stddev = 1/lambda_b), name = 'b4')\n",
    "    output4 = tf.nn.sigmoid(tf.add(tf.matmul(X3_, W4), b4), name = 'output4')\n",
    "    X4 = tf.random_normal(shape = [batch_size, hidden_dim], mean = output4, stddev = 1/lambda_X, name = 'X4')\n",
    "    return output4, X4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope(\"d_layer_1\") as scope:\n",
    "    output4, X4 = d_layer_1(X3_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d_layer_2(X4):\n",
    "    W5 = tf.Variable(tf.random_normal(shape = [hidden_dim, hidden_dim], mean = 0., stddev = 1/lambda_W), name = 'W5')\n",
    "    b5 = tf.Variable(tf.random_normal(shape = [batch_size, hidden_dim], mean = 0., stddev = 1/lambda_b), name = 'b5')\n",
    "    output5 = tf.nn.sigmoid(tf.add(tf.matmul(X4, W5), b5), name = 'output5')\n",
    "    X5 = tf.random_normal(shape = [batch_size, hidden_dim], mean = output5, stddev = 1/lambda_X, name = 'X5')\n",
    "    return output5, X5"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('d_layer_2') as scope:\n",
    "    output5, X5 = d_layer_2(X4)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def d_layer_3(X5):\n",
    "    W6 = tf.Variable(tf.random_normal(shape = [hidden_dim, input_dim], mean = 0., stddev = 1/lambda_W), name = 'W6')\n",
    "    b6 = tf.Variable(tf.random_normal(shape = [batch_size, input_dim], mean = 0., stddev = 1/lambda_b), name = 'b6')\n",
    "    output6 = tf.nn.sigmoid(tf.add(tf.matmul(X5, W6), b6), name = 'output6')\n",
    "    X6 = tf.random_normal(shape = [batch_size, input_dim], mean = output6, stddev = 1/lambda_X, name = 'X6')\n",
    "    return output6, X6"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.name_scope('d_layer_3') as scope:\n",
    "    output6, X6 = d_layer_3(X5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "[noise, W1, b1, W2, b2, W3, b3, W4, b4, W5, b5, W6, b6] = tf.global_variables()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "log_likelihood = -tf.multiply(lambda_X, tf.add_n([tf.reduce_mean(tf.square(tf.subtract(output1, X1))), \n",
    "                         tf.reduce_mean(tf.square(tf.subtract(output2, X2))),\n",
    "                         tf.reduce_mean(tf.square(tf.subtract(output3, X3_))), \n",
    "                         tf.reduce_mean(tf.square(tf.subtract(output4, X4))),\n",
    "                         tf.reduce_mean(tf.square(tf.subtract(output5, X5))), \n",
    "                         tf.reduce_mean(tf.square(tf.subtract(output6, X6)))]))/2 - tf.add_n([tf.add(tf.multiply(lambda_W, tf.reduce_mean(tf.square(W1))), tf.multiply(lambda_b, tf.reduce_mean(tf.square(b1)))),\n",
    "                 tf.add(tf.multiply(lambda_W, tf.reduce_mean(tf.square(W2))), tf.multiply(lambda_b, tf.reduce_mean(tf.square(b2)))),\n",
    "                 tf.add(tf.multiply(lambda_W, tf.reduce_mean(tf.square(W3))), tf.multiply(lambda_b, tf.reduce_mean(tf.square(b3)))),\n",
    "                 tf.add(tf.multiply(lambda_W, tf.reduce_mean(tf.square(W4))), tf.multiply(lambda_b, tf.reduce_mean(tf.square(b4)))),\n",
    "                 tf.add(tf.multiply(lambda_W, tf.reduce_mean(tf.square(W5))), tf.multiply(lambda_b, tf.reduce_mean(tf.square(b5)))),\n",
    "                 tf.add(tf.multiply(lambda_W, tf.reduce_mean(tf.square(W6))), tf.multiply(lambda_b, tf.reduce_mean(tf.square(b6))))])\n",
    "\n",
    "loss = -log_likelihood"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "opt = tf.train.AdadeltaOptimizer(learning_rate=learning_rate)\n",
    "train = opt.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "init = tf.global_variables_initializer()\n",
    "sess.run(init)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "model_id = datetime.fromtimestamp(time()).strftime('%Y-%m-%d_%H:%M:%S')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "save_dir = './SDAE/%s' %(model_id)\n",
    "save_summary_path = os.path.join(save_dir, 'model_summary')\n",
    "save_variable_path = os.path.join(save_dir, 'model_variables')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "if not os.path.exists(save_dir):\n",
    "    os.makedirs(save_dir)\n",
    "if not os.path.exists(save_summary_path):\n",
    "    os.makedirs(save_summary_path)\n",
    "if not os.path.exists(save_variable_path):\n",
    "    os.makedirs(save_variable_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "merged = tf.summary.merge_all(key = 'summaries')\n",
    "summary_writer = tf.summary.FileWriter(save_summary_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "generator = BatchGenerator(sample_mtx, sample_mtx, batch_size)\n",
    "X, _ = generator.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false,
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "for i in range(50000):\n",
    "    sess.run(train, feed_dict={x_data:X})\n",
    "    if (i+1)%10 == 0:\n",
    "        temp_loss = sess.run(loss, feed_dict={x_data:X})\n",
    "        print(temp_loss)\n",
    "    X, _ = generator.next_batch()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "for v in tf.trainable_variables():\n",
    "    print(v.name, end=' ')\n",
    "    print(v.get_shape())\n",
    "    fname = v.name.replace('/','-')\n",
    "    fname = '{}.csv'.format(fname)\n",
    "    fname = os.path.join(save_variable_path, fname)\n",
    "    np.savetxt(fname, v.eval(session=sess), delimiter=',')"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
